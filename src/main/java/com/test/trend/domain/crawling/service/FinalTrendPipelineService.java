package com.test.trend.domain.crawling.service;

import com.test.trend.domain.crawling.content.ContentDetail;
import com.test.trend.domain.crawling.content.ContentDetailRepository;
import com.test.trend.domain.crawling.freq.WordFrequencyService;
import com.test.trend.domain.crawling.insight.WeeklyInsightService;
import com.test.trend.domain.crawling.keyword.Keyword;
import com.test.trend.domain.crawling.keyword.KeywordRepository;
import com.test.trend.domain.crawling.keyword.RisingKeywordDto;
import com.test.trend.domain.crawling.score.TrendScoreService;
import com.test.trend.domain.crawling.targeturl.SearchResultDto;
import com.test.trend.domain.crawling.targeturl.TargetUrl;
import com.test.trend.domain.crawling.targeturl.TargetUrlRepository;
import com.test.trend.enums.TargetUrlStatus;
import com.test.trend.enums.YesNo;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDateTime;
import java.util.List;

@Slf4j
@Service
@RequiredArgsConstructor
public class FinalTrendPipelineService {

    // --- Services ---
    private final MusinsaCategoryCrawlerService musinsaService;
    private final SearchApiService searchApiService;
    private final JsoupCrawlerService jsoupService;
    private final WordFrequencyService wordFrequencyService;
    private final DataLabApiService dataLabApiService;
    private final TrendScoreService trendScoreService;
    private final WeeklyInsightService weeklyInsightService;

    // --- Repositories ---
    private final ContentDetailRepository contentDetailRepo;
    private final KeywordRepository keywordRepo;
    private final TargetUrlRepository targetUrlRepo;

    /**
     * ğŸš€ [ë©”ì¸ íŒŒì´í”„ë¼ì¸] ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
     * ìŠ¤ì¼€ì¤„ëŸ¬ë‚˜ ê´€ë¦¬ì ì»¨íŠ¸ë¡¤ëŸ¬ì—ì„œ ì´ ë©”ì„œë“œë§Œ í˜¸ì¶œí•˜ë©´ ë©ë‹ˆë‹¤.
     */
    public void executeFullPipeline() {
        long startTime = System.currentTimeMillis();
        log.info("========== [Pipeline] Daily Trend Analysis Started ==========");

        // 1. ë¬´ì‹ ì‚¬ í¬ë¡¤ë§ (í‚¤ì›Œë“œ ë°œêµ´)
        log.info(">>> [Step 1] Crawling Rising Keywords from Musinsa...");
        List<RisingKeywordDto> risingKeywords = musinsaService.crawlRisingKeywords();
        log.info("   -> Found {} keywords.", risingKeywords.size());

        // 2. ê° í‚¤ì›Œë“œë³„ ìƒì„¸ í”„ë¡œì„¸ìŠ¤ (ì €ì¥ -> ë¸”ë¡œê·¸ìˆ˜ì§‘ -> ë¶„ì„ -> ë°ì´í„°ë©)
        log.info(">>> [Step 2~4] Processing Each Keyword...");
        int successCount = 0;
        for (RisingKeywordDto rk : risingKeywords) {
            try {
                processSingleKeywordFlow(rk);
                successCount++;
            } catch (Exception e) {
                // í‚¤ì›Œë“œ í•˜ë‚˜ê°€ ì‹¤íŒ¨í•´ë„ ì „ì²´ íŒŒì´í”„ë¼ì¸ì€ ë©ˆì¶”ì§€ ì•ŠìŒ
                log.error("   -> [Skip] Failed to process keyword: {}", rk.getKeyword(), e);
            }
        }
        log.info("   -> Processed {}/{} keywords successfully.", successCount, risingKeywords.size());

        // 5. íŠ¸ë Œë“œ ì ìˆ˜ ì¬ê³„ì‚° (ì „ì²´ í‚¤ì›Œë“œ ëŒ€ìƒ)
        log.info(">>> [Step 5] Recalculating Trend Scores...");
        try {
            trendScoreService.recalcTodayScores();
        } catch (Exception e) {
            log.error(">>> [TrendScore] Calculation Failed", e);
        }

        // 6. AI ì¸ì‚¬ì´íŠ¸ ìƒì„± (ìƒìœ„ í‚¤ì›Œë“œ ëŒ€ìƒ)
        log.info(">>> [Step 6] Generating Weekly Insights (AI)...");
        generateInsightsForKeywords(risingKeywords);

        long endTime = System.currentTimeMillis();
        log.info("========== [Pipeline] Finished in {} ms ==========", (endTime - startTime));
    }

    /**
     * ê°œë³„ í‚¤ì›Œë“œ ì²˜ë¦¬ ë¡œì§ (ë³µì¡ë„ ë¶„ë¦¬)
     * í‚¤ì›Œë“œ ì €ì¥ -> ë¸”ë¡œê·¸ URL ìˆ˜ì§‘ -> ë³¸ë¬¸ í¬ë¡¤ë§ -> ë°ì´í„°ë© ì§€í‘œ
     */
    private void processSingleKeywordFlow(RisingKeywordDto rk) {
        String keywordStr = rk.getKeyword();
        log.info("   -> Processing: [{}] ({})", keywordStr, rk.getCategory());

        // 2-1) Keyword í…Œì´ë¸” ì €ì¥/ì—…ë°ì´íŠ¸
        Keyword keywordEntity = getOrCreateKeyword(keywordStr, rk.getCategory(), rk.getImgUrl());

        // 2-2) ë„¤ì´ë²„ ë¸”ë¡œê·¸ URL ìˆ˜ì§‘
        List<SearchResultDto> searchResults = searchApiService.searchBlogUrls(keywordStr);

        // 2-3) ë³¸ë¬¸ í¬ë¡¤ë§ & í˜•íƒœì†Œ ë¶„ì„ (ë³‘ë ¬ ì²˜ë¦¬)
        // ë³‘ë ¬ ìŠ¤íŠ¸ë¦¼ì€ ì†ë„ëŠ” ë¹ ë¥´ì§€ë§Œ DB ì»¤ë„¥ì…˜ì„ ë§ì´ ì“¸ ìˆ˜ ìˆìœ¼ë‹ˆ ì£¼ì˜
        searchResults.parallelStream().forEach(dto -> {
            try {
                crawlAndAnalyzePost(keywordEntity, dto);
            } catch (Exception e) {
                log.debug("      -> [Blog Fail] {}", e.getMessage()); // ìƒì„¸ ë¡œê·¸ëŠ” debug ë ˆë²¨ë¡œ
            }
        });

        // 2-4) ë°ì´í„°ë© ì§€í‘œ ìˆ˜ì§‘
        try {
            dataLabApiService.fetchAndSaveTrend(keywordEntity.getSeqKeyword());
        } catch (Exception e){
            log.warn("      -> [DataLab Fail] {}", e.getMessage());
        }

        // 2-5) Rate Limiting (ì°¨ë‹¨ ë°©ì§€ìš© ë”œë ˆì´)
        try { Thread.sleep(2000); } catch (InterruptedException ignored) {}
    }

    /**
     * ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ í•˜ë‚˜ì— ëŒ€í•œ í¬ë¡¤ë§ ë° ë¶„ì„
     */
    private void crawlAndAnalyzePost(Keyword keywordEntity, SearchResultDto dto) {
        // [A] TargetUrl ì €ì¥ (ì¤‘ë³µ ë°©ì§€ ë¡œì§ì€ Repo ë ˆë²¨ì´ë‚˜ Service ì•ë‹¨ì— ìˆìœ¼ë©´ ì¢‹ìŒ)
        TargetUrl targetUrl;
        try {
            targetUrl = TargetUrl.builder()
                    .keyword(keywordEntity)
                    .url(dto.url())
                    .title(dto.title())
                    .postDate(dto.postDate())
                    .domain("NAVER_BLOG")
                    .status(TargetUrlStatus.WAIT)
                    .build();
            targetUrl = targetUrlRepo.save(targetUrl);
        } catch (Exception e) {
            // ì´ë¯¸ ì¡´ì¬í•˜ëŠ” URLì´ê±°ë‚˜ ì €ì¥ ì‹¤íŒ¨ ì‹œ ìŠ¤í‚µ
            return;
        }

        // [B] Jsoup ìƒì„¸ í¬ë¡¤ë§
        JsoupCrawlerService.CrawledResult result = jsoupService.verifyAndGetContent(dto.url());

        if (result != null && result.content() != null && !result.content().isBlank()) {
            // [C] ContentDetail ì €ì¥
            ContentDetail content = ContentDetail.builder()
                    .targetUrl(targetUrl)
                    .bodyText(result.content())
                    .imageUrl(result.imageUrl())
                    .crawledAt(LocalDateTime.now())
                    .engineType("Jsoup")
                    .status("SUCCESS")
                    .analyzedYn(YesNo.N)
                    .build();
            contentDetailRepo.save(content);

            // [D] ìƒíƒœ ì—…ë°ì´íŠ¸
            targetUrl.setStatus(TargetUrlStatus.CRAWLED);
            targetUrlRepo.save(targetUrl);

            // [E] í˜•íƒœì†Œ ë¶„ì„ (ì¦‰ì‹œ ì‹¤í–‰)
            try {
                wordFrequencyService.analyzeAndSave(content, result.content());
            } catch (Exception e) {
                log.warn("      -> Word Analysis Error: {}", e.getMessage());
            }
        } else {
            // ì‹¤íŒ¨ ì²˜ë¦¬
            targetUrl.setStatus(TargetUrlStatus.FAILED);
            targetUrlRepo.save(targetUrl);
        }
    }

    /**
     * AI ì¸ì‚¬ì´íŠ¸ ìƒì„± (ì¼ê´„ ì²˜ë¦¬)
     */
    private void generateInsightsForKeywords(List<RisingKeywordDto> keywords) {
        for (RisingKeywordDto rk : keywords) {
            try {
                Keyword entity = keywordRepo.findByKeyword(rk.getKeyword()).orElse(null);
                if (entity != null) {
                    weeklyInsightService.createWeeklyInsight(entity);
                }
            } catch (Exception e) {
                log.error("   -> [Insight Fail] {}", rk.getKeyword(), e);
            }
        }
    }

    /**
     * í‚¤ì›Œë“œ ì—”í‹°í‹° ì¡°íšŒ ë˜ëŠ” ìƒì„±
     */
    private Keyword getOrCreateKeyword(String keywordStr, String category, String imgUrl) {
        return keywordRepo.findByKeyword(keywordStr)
                .map(existing -> {
                    boolean updated = false;
                    if (category != null && !category.equals("ê¸°íƒ€") && !category.equals(existing.getCategory())) {
                        existing.setCategory(category);
                        updated = true;
                    }
                    if (imgUrl != null && !imgUrl.isBlank() && !imgUrl.equals(existing.getImgUrl())) {
                        existing.setImgUrl(imgUrl);
                        updated = true;
                    }
                    return updated ? keywordRepo.save(existing) : existing;
                })
                .orElseGet(() -> {
                    Keyword k = new Keyword();
                    k.setKeyword(keywordStr);
                    k.setCategory(category);
                    k.setImgUrl(imgUrl);
                    k.setIsActive(YesNo.Y);
                    return keywordRepo.save(k);
                });
    }

    /**
     * [ìœ í‹¸] ë¶„ì„ ì•ˆ ëœ ë°ì´í„° ìˆ˜ë™ ì¬ì²˜ë¦¬ìš© (í•„ìš”ì‹œ ì‚¬ìš©)
     */
    @Transactional
    public void retryFailedWordAnalysis() {
        List<ContentDetail> targets = contentDetailRepo.findByAnalyzedYn(YesNo.N);
        log.info(">>> Retrying word analysis for {} items...", targets.size());

        for (ContentDetail cd : targets) {
            try {
                wordFrequencyService.analyzeAndSave(cd, cd.getBodyText());
            } catch (Exception e) {
                log.error("   -> Retry failed for seq={}", cd.getSeqDetail());
            }
        }
    }
}